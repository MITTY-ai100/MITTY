from dotenv import load_dotenv
import os
from openai import OpenAI
import streamlit as st

load_dotenv()

client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
)

st.title("KoJaem's bot ğŸš€")

type = st.radio(
    "ì–´ë–¤ ì‘ì—…ì´ í•„ìš”í•˜ì„¸ìš”?",
    [":rainbow[ì´ë¯¸ì§€ ìƒì„±]", "ë¹„ë””ì˜¤ ìƒì„±", "ìŒì„±íŒŒì¼!"],
    captions = ["í•„ìš”í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.", "ì•„ì§ êµ¬í˜„ ì•ˆëì–´ìš”ğŸ˜¢", "./speech.mp3"])

keyword = st.text_input('í•„ìš”í•œê²ƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”.')

if st.button('ìš”ì²­í•˜ê¸°'):
  if(type == ':rainbow[ì´ë¯¸ì§€ ìƒì„±]'):
    with st.spinner('ì´ë¯¸ì§€ ìƒì„±ì¤‘...'):
        response = client.images.generate(
          model="dall-e-3",
          prompt=f'{keyword}',
          quality="standard",
          size="1024x1024",
          n=1,
      )
        image_url = response.data[0].url
        st.image(image_url)
  elif(type=='ë¹„ë””ì˜¤ ìƒì„±'):
     st.write('ì•„ì§ ì•ˆëë‹¤ë‹ˆê¹Œìš” ğŸ˜¢ğŸ˜¢ğŸ˜¢')
  else:
     with st.spinner('ì´ë¯¸ì§€ ìƒì„±ì¤‘...'):
        audio_file= open("./speech.mp3", "rb")
        transcription = client.audio.transcriptions.create(
           model="whisper-1", 
           file=audio_file
           )
        audioText = transcription.text
        print(audioText)
        response = client.images.generate(
          model="dall-e-3",
          prompt=f'{audioText}',
          quality="standard",
          size="1024x1024",
          n=1,
      )
        image_url = response.data[0].url
        st.image(image_url)
